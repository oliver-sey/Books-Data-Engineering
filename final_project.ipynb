{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books Data Engineering ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spring 2024, by Oliver Seymour\n",
    "\n",
    "\n",
    "#### My Data Sources:\n",
    "\n",
    "Goodreads books and reviews: https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks\n",
    "\n",
    "Audible books and reviews: https://www.kaggle.com/code/satyanarayanam/cleaning-audible-dataset/input\n",
    "\n",
    "***add another here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment these!!\n",
    "# %pip install pandas\n",
    "# %pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on the import:\n",
    "\n",
    "I was getting errors when importing goodreads.csv (the dataset on books and reviews from Goodreads), related to finding the wrong number of columns.\n",
    "\n",
    "I manually fixed row 3350 where a comma before 'Jr.' in an author's name was causing issues since a comma is the delimiter\n",
    "\n",
    "Fixed a similar comma issue in row 4704\n",
    "\n",
    "Removed a comma in the middle of \"James Wesley Rawles\" (the only author's name) on row 5879\n",
    "\n",
    "Fixed a similar issue in row 8981 - changed author column from 'James Brown, Son & Ferguson' to 'James Brown and Son & Ferguson'. I know this is a pretty manual edit of the data, but I felt like it didn't make sense for this to get split into the three authors 'James Brown', 'Son', and 'Ferguson'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audible_df = pd.read_csv('Data/audible_copy_pasted.csv', encoding='utf-8')\n",
    "print(\"data from audible:\")\n",
    "display(audible_df.head())\n",
    "\n",
    "goodreads_df = pd.read_csv('Data/goodreads_copy_pasted.csv', sep=',', encoding='utf-8', on_bad_lines='warn')\n",
    "print(\"data from goodreads:\")\n",
    "display(goodreads_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that there are no character encoding issues on a couple rows that had problems before\n",
    "display(audible_df[(audible_df['time'] == '9 hrs and 17 mins') & (audible_df['language'] == 'mandarin_chinese')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Goodreads dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(goodreads_df.shape)\n",
    "display(goodreads_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: explore more in the goodreads data set!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Audible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape?\n",
    "audible_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many NAs are there?\n",
    "audible_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if the author column always starts with 'Writtenby:'\n",
    "display(audible_df[~audible_df['author'].str.contains(pat=r'^Writtenby:', regex=True)])\n",
    "# wow ok, there are 0 rows that don't have that starting, that will be easy to clean\n",
    "\n",
    "# and if the narrator column always starts with 'Narratedby:'\n",
    "display(audible_df[~audible_df['narrator'].str.contains(pat=r'^Narratedby:', regex=True)])\n",
    "# ok nice, once again they all follow that pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know these columns always start with 'Writtenby:' and 'Narratedby:', how can we split up the first and last names?\n",
    "# regex: first 'Writtenby: and then either one or more of: (a capital letter followed by one or more lowercase letters), \n",
    "# basically just FirstNameOrMaybeMoreName\n",
    "# or (one or more of: (a capital letter followed by a period), i.e. for an initial, followed by a capital letter and then one or more lowercase\n",
    "# basically A.B.LastNameMaybeMore\n",
    "\n",
    "\n",
    "# display(audible_df[~audible_df[\"author\"].str.contains(pat=r\"^Writtenby:( (([A-Z][a-z]+)+ | (([A-Z][.])+[A-Z][a-z]+))+[,]* )\")])\n",
    "# display(audible_df[audible_df[\"author\"].str.contains(pat=r\"^Writtenby:((([A-Z][.])+[A-Z][a-z]+)+[,]*)\")])\n",
    "display(audible_df[~audible_df[\"author\"].str.contains(pat=r\"^Writtenby:([A-Z][a-z]+)+\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for inconsistencies in the formatting of the 'time' column\n",
    "# do they all have 'and'?\n",
    "display(audible_df[~audible_df['time'].str.contains(pat=r'and', regex=True)].head())\n",
    "# ok not all do\n",
    "\n",
    "# do they all follow the <numbers><space><letters> etc. pattern?\n",
    "display(audible_df[~audible_df['time'].str.contains(pat=r'^\\d+\\s+[A-Za-z]+')].head())\n",
    "\n",
    "# let's get the unique values:\n",
    "audible_df.loc[~audible_df['time'].str.contains(r'^\\d+\\s+[A-Za-z]+', regex=True), 'time'].unique()\n",
    "# ok seems like it always contains 'and', except if the value is 'Less than 1 minute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploring the stars column\n",
    "# let's see what values there are:\n",
    "audible_df['stars'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often is the stars column 'Not rated yet', or some other string that doesn't contain a digit?\n",
    "display(audible_df[~audible_df['stars'].str.contains(r'\\d')].shape)\n",
    "# wow that's a lot of books that aren't rated yet!\n",
    "display(audible_df[~audible_df['stars'].str.contains(r'\\d')])\n",
    "\n",
    "# what unique values are there?\n",
    "audible_df[~audible_df['stars'].str.contains(r'\\d')]['stars'].unique()\n",
    "# ok seems to just be 'Not rated yet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the values in 'stars' all follow the same pattern?\n",
    "print(\"check that it's always out of 5 stars:\")\n",
    "display(audible_df[~(audible_df['stars'].str.contains(r'out of 5 stars') \n",
    "\t\t\t\t\t | audible_df['stars'].str.contains(r'Not rated yet'))]['stars'].unique())\n",
    "\n",
    "print(\"check that its always either an integer number of stars, or 1 decimal digit, or Not rated yet:\")\n",
    "# at the start of the string, one digit, then an optional period, then an optional digit, then it has to be a space\n",
    "display(audible_df[~(audible_df['stars'].str.contains(r'^\\d[.]*\\d*\\s') \n",
    "\t\t\t\t\t | audible_df['stars'].str.contains(r'Not rated yet'))]['stars'].unique())\n",
    "\n",
    "print(\"values in 'stars' where they don't follow the 'X.X out of 5 starsXXX (1-3 digits) rating[maybe an 's']' or 'Not rated yet' pattern:\")\n",
    "display(audible_df[~(audible_df['stars'].str.contains(r'\\d[.]*\\d* out of 5 stars\\d{1,3} rating[s]*') \n",
    "\t\t\t\t\t | audible_df['stars'].str.contains(r'Not rated yet'))]['stars'].unique())\n",
    "\n",
    "print(\"also excluding e.g. '4.5 out of 5 stars1,869 ratings', with the comma in the ratings count:\")\n",
    "display(audible_df[~(audible_df['stars'].str.contains(r'\\d[.]*\\d* out of \\d stars\\d{1,3} rating[s]*') \n",
    "\t\t\t\t\t | audible_df['stars'].str.contains(r'Not rated yet')\n",
    "\t\t\t\t\t | audible_df['stars'].str.contains(r'\\d[.]*\\d* out of \\d stars\\d+[,]\\d+ rating[s]*')\n",
    "\t\t\t\t\t )]['stars'].unique())\n",
    "\n",
    "# ok it seems like we only have a few possible patterns in this column\n",
    "# and the stars are always out of 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the release date column always follow the pattern <numbers> - <numbers> - <numbers>?\n",
    "display(audible_df[~audible_df['releasedate'].str.contains(r'^\\d+-\\d+-\\d+', regex=True)])\n",
    "# Ok nice they all follow that pattern\n",
    "\n",
    "display(audible_df[~audible_df['releasedate'].str.contains(r'^\\d{2}-\\d{2}-\\d{4}', regex=True)])\n",
    "# but it appears they don't always follow DD-MM-YYYY, sometimes it is D-M-YYYY, and sometimes it is just YY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what values are there in language?\n",
    "display(audible_df['language'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the ****third dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Goodreads dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Audible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep copy\n",
    "cleaned_audible_df = audible_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's clean up the price column and get it into a float\n",
    "# display(cleaned_audible_df[cleaned_audible_df['cleaned_price'].str.contains(',')])\n",
    "\n",
    "# since there are commas in the numbers, e.g. 1,234.00, we will have to get rid of commas\n",
    "cleaned_audible_df['price_no_commas'] = cleaned_audible_df['price'].str.replace(',', '')\n",
    "\n",
    "# check if the comma removing worked correctly:\n",
    "# .option_context(\"display.min_rows\", 10000):\n",
    "print('rows where price contains a comma:')\n",
    "display(cleaned_audible_df[cleaned_audible_df['price'].str.contains(',')])\n",
    "\n",
    "print(\"Check the NA's:\")\n",
    "display(cleaned_audible_df.isna().sum())\n",
    "# display(cleaned_audible_df[cleaned_audible_df['price_no_commas'].isna()])\n",
    "\n",
    "print(\"rows where price has a non-zero digit after the decimal place:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['price_no_commas'].str.contains(r'[.][1-9]', regex=True, na=False)])\n",
    "# ok there are some prices that have a fraction, so we can't just make them ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what unique values are in the price column besides just digits\n",
    "cleaned_audible_df[cleaned_audible_df['price'].str.contains(r'[A-Za-z]', regex=True)]['price'].unique()\n",
    "# Ok nice only 'Free', let's make those 0\n",
    "\n",
    "cleaned_audible_df['cleaned_price'] = cleaned_audible_df['price_no_commas'].apply(lambda value: 0 if value == 'Free' else value)\n",
    "\n",
    "# let's also convert to a float\n",
    "cleaned_audible_df['cleaned_price'] = cleaned_audible_df['cleaned_price'].astype(float)\n",
    "\n",
    "display(cleaned_audible_df.head())\n",
    "\n",
    "display(cleaned_audible_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# looks good, now we can drop the other columns and rename cleaned_price\n",
    "cleaned_audible_df.drop(columns=['price', 'price_no_commas'], inplace=True)\n",
    "cleaned_audible_df.rename(columns= {'cleaned_price' : 'cleaned_price_rupees'}, inplace=True)\n",
    "\n",
    "print(\"After dropping and renaming:\")\n",
    "display(cleaned_audible_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: !!!!! have to deal with weird character encoding issues in the audible dataset as well\n",
    "# like ç¬¬äºŒåäº”è©±ã‚µãƒ³ãƒ»ãƒŸã‚·ã‚§ãƒ«ã®ã„ã„ã...\tWrittenby:æ£®æœ¬å“²éƒŽ\tNarratedby:å°é‡Žç”°è‹±ä¸€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the author and narrator columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In my exploration I found that every row in the author and narrator column started with\n",
    "# 'Writtenby:' and 'Narratedby:', so let's remove that\n",
    "\n",
    "# replace 'Writtenby:' with an empty string\n",
    "cleaned_audible_df['author'] = cleaned_audible_df['author'].str.replace(pat=r'^Writtenby:', repl='', regex=True)\n",
    "\n",
    "# replace 'Narrattedby:' with an empty string\n",
    "cleaned_audible_df['narrator'] = cleaned_audible_df['narrator'].str.replace(pat=r'^Narratedby:', repl='', regex=True)\n",
    "\n",
    "display(cleaned_audible_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the releasedate column (converting to timestamp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the release date to a datetime object\n",
    "# **Important note, they seem to be in a DD-MM-YYYY (or sometimes D-M-YY, etc. but day first) format, \n",
    "# since there are some dates like 30-10-18, 25-11-14 (so the day must be first), but there is also 1-5-2018\n",
    "cleaned_audible_df['cleaned_releasedate'] = pd.to_datetime(cleaned_audible_df['releasedate'], dayfirst=True, format='mixed')\n",
    "\n",
    "# temporarily display a lot of rows to check it worked\n",
    "with pd.option_context(\"display.min_rows\", 10):\n",
    "\t# look at just rows where releasedate had a weird format to especially make sure it worked for those\n",
    "\tdisplay(cleaned_audible_df[~cleaned_audible_df['releasedate'].str.contains(r'\\d{2}-\\d{2}-\\d{4}', regex=True)])\n",
    "\tdisplay(cleaned_audible_df)\n",
    "\n",
    "# ok seems to have worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are no weird values in cleaned_releasedate\n",
    "print(\"min release date values:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] == cleaned_audible_df['cleaned_releasedate'].min()])\n",
    "# ok the min values look reasonable\n",
    "\n",
    "# check books that were released after today's date\n",
    "print(\"release date values that are after today's date:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] > pd.to_datetime('today').normalize()])\n",
    "# I don't think this is a mistake since one of the original releasedate values is '9-8-2024'\n",
    "# These have very weird character encoding issues and I don't think it makes sense to have books that aren't release yet\n",
    "# so I'm going to drop these\n",
    "\n",
    "cleaned_audible_df = cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] <= pd.to_datetime('today').normalize()]\n",
    "print(\"new max release date value:\")\n",
    "display(cleaned_audible_df['cleaned_releasedate'].max())\n",
    "# ok nice, now the max value was released about 2 weeks ago, that seems reasonable\n",
    "\n",
    "# now let's drop the releasedate column\n",
    "cleaned_audible_df.drop(columns=['releasedate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the time column and extracting hours and mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt at converting the time column by splitting it into hours, mins, etc. components in different columns and then combining again\n",
    "print(\"df with the hours extracted:\")\n",
    "display(cleaned_audible_df['time'].str.extract(pat=r'([A-Za-z]+\\s*)+')[0].unique())\n",
    "\n",
    "# at the start of the string, get one or more digits, then a white space, hr, maybe an s\n",
    "# but only keep the digits\n",
    "# i.e. we get '8 hrs' or '1 hr' and we only keep the 8 or 1\n",
    "cleaned_audible_df['hours'] = cleaned_audible_df['time'].str.extract(pat=r'^(\\d+)\\shr[s]*')\n",
    "# seems to have worked\n",
    "# we have an NA if it is 0 hours, so let's fill the NAs with 0's\n",
    "cleaned_audible_df['hours'] = cleaned_audible_df['hours'].fillna(0)\n",
    "\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# check that it worked for when it is just '1 hr', not hrs\n",
    "print(\"rows with time == '1 hr':\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['time'] == '1 hr'])\n",
    "\n",
    "# check that the fillNA worked correctly\n",
    "print(\"rows with 0 in the hours column:\")\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df[cleaned_audible_df['hours'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the minutes\n",
    "# cleaned_audible_df['minutes'] = cleaned_audible_df['time'].str.extract(r'')\n",
    "cleaned_audible_df[cleaned_audible_df['time'].str.contains(r'min$', regex=True)]\n",
    "# ok it seems we have to be careful with not getting 'Less than 1 minute' and something like '1 hr and 1 min' mixed up\n",
    "\n",
    "# one or more digits, then 1 whitespace, then 'min', then maybe an s, all this at the end of the string\n",
    "# only capture the digits though\n",
    "# it is important that it's at the end of the string so we don't accidentally capture the 1 from 'Less than 1 minute', \n",
    "# we only want the number when the string ends in min or mins\n",
    "print(\"df with minutes extracted:\")\n",
    "cleaned_audible_df['minutes'] = cleaned_audible_df['time'].str.extract(r'(\\d+)\\smin[s]*$')\n",
    "# cleaned_audible_df[cleaned_audible_df['time'].str.contains(r'(\\d+\\smin[s]*$)')]\n",
    "\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# check that it correctly did NA for rows where there are no minutes\n",
    "print(\"rows with NA in the minutes column:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['minutes'].isna()])\n",
    "\n",
    "# the minutes column seems to have worked nicely, let's fill in the NAs with 0's\n",
    "cleaned_audible_df['minutes'] = cleaned_audible_df['minutes'].fillna(0)\n",
    "\n",
    "print(\"cleaned_audible_df with minutes NAs filled in with 0's:\")\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the columns to integer\n",
    "cleaned_audible_df['hours'] = cleaned_audible_df['hours'].astype(int)\n",
    "cleaned_audible_df['minutes'] = cleaned_audible_df['minutes'].astype(int)\n",
    "\n",
    "cleaned_audible_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see how many rows are only 1 minute, to help us figure out what to do with the 'Less than 1 minute'\n",
    "cleaned_audible_df[(cleaned_audible_df['hours'] == 0) & (cleaned_audible_df['minutes'] == 1)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what to do with rows where it is 'Less than 1 minute'????\n",
    "# let's see what unique values there are in the time column where we got NA for both hours and mins, and filled them both in with 0's:\n",
    "display(cleaned_audible_df[(cleaned_audible_df['hours'] == 0) & (cleaned_audible_df['minutes'] == 0)]['time'].unique())\n",
    "# Ok, just 'Less than 1 minute'. I will have to figure out how to take care of this\n",
    "\n",
    "# how many are there?\n",
    "print(\"# of rows where time is 'Less than 1 minute':\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['time'] == 'Less than 1 minute'].shape[0])\n",
    "\n",
    "# ok since it is just 61 in 88k, and since we don't have any precision smaller than minutes, \n",
    "# I think we should just round this to 1 minute\n",
    "cleaned_audible_df.loc[cleaned_audible_df['time'] == 'Less than 1 minute', 'minutes'] = 1\n",
    "\n",
    "print(\"rows where 'time' is 'Less than 1 minute':\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['time'] == 'Less than 1 minute'].head())\n",
    "\n",
    "# ok looks good, now that we have a nice hours and minutes column, we can convert that to a timedelta and drop 'time'\n",
    "# cleaned_audible_df.drop(columns=['time'], inplace=True)\n",
    "\n",
    "# convert the hours and minutes columns to separate columns that are a pandas time delta\n",
    "cleaned_audible_df['hours_timedelta'] = pd.to_timedelta(cleaned_audible_df['hours'], unit='h')\n",
    "cleaned_audible_df['minutes_timedelta'] = pd.to_timedelta(cleaned_audible_df['minutes'], unit='m')\n",
    "\n",
    "# add the two timedelta columns together to get the full runtime\n",
    "cleaned_audible_df['cleaned_runtime'] = cleaned_audible_df['hours_timedelta'] + cleaned_audible_df['minutes_timedelta']\n",
    "\n",
    "print(\"With timedelta columns:\")\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# drop the unnecessary columns\n",
    "cleaned_audible_df.drop(columns=['hours', 'minutes', 'hours_timedelta', 'minutes_timedelta'], inplace=True)\n",
    "print(\"With columns dropped:\")\n",
    "display(cleaned_audible_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the stars column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok we know there are only a few patterns that values in this column follow\n",
    "# at the start of the string, get a number and then optionally a decimal and another number\n",
    "# (we know from the exploration that it's only ever an integer for the stars, or one decimal place)\n",
    "cleaned_audible_df['star_count'] = cleaned_audible_df['stars'].str.extract(r'^(\\d[.]*\\d*)')\n",
    "\n",
    "cleaned_audible_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the ****third dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just a test for now\n",
    "# test_integrated_df = goodreads_df.merge(audible_df, left_on='title', right_on='name')\n",
    "# test_integrated_df = audible_df.merge(goodreads_df, left_on='title', right_on='name')\n",
    "\n",
    "# test_integrated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
