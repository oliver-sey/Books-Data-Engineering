{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books Data Engineering ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spring 2024, by Oliver Seymour\n",
    "\n",
    "\n",
    "#### My Data Sources:\n",
    "\n",
    "Goodreads books and reviews: https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks\n",
    "\n",
    "Audible books and reviews: https://www.kaggle.com/code/satyanarayanam/cleaning-audible-dataset/input\n",
    "\n",
    "***add another here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment these!!\n",
    "# %pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audible_df = pd.read_csv('Data/audible.csv')#, encoding='ISO-8859-1')\n",
    "display(audible_df.head())\n",
    "\n",
    "# TODO: fix issues with goodreads import!!\n",
    "# used the chardet library to find with ~70% confidence that this is the right encoding for this file\n",
    "# goodreads_df = pd.read_csv(sep=';', encoding='ISO-8859-1')\n",
    "# display(audible_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Goodreads dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Audible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.min_rows', 10000):\n",
    "\tdisplay(cleaned_audible_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the shape?\n",
    "audible_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many NAs are there?\n",
    "audible_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if the author column always starts with 'Writtenby:'\n",
    "display(audible_df[~audible_df['author'].str.contains(pat=r'^Writtenby:', regex=True)])\n",
    "# wow ok, there are 0 rows that don't have that starting, that will be easy to clean\n",
    "\n",
    "# and if the narrator column always starts with 'Narratedby:'\n",
    "display(audible_df[~audible_df['narrator'].str.contains(pat=r'^Narratedby:', regex=True)])\n",
    "# ok nice, once again they all follow that pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we know these columns always start with 'Writtenby:' and 'Narratedby:', how can we split up the first and last names?\n",
    "# regex: first 'Writtenby: and then either one or more of: (a capital letter followed by one or more lowercase letters), \n",
    "# basically just FirstNameOrMaybeMoreName\n",
    "# or (one or more of: (a capital letter followed by a period), i.e. for an initial, followed by a capital letter and then one or more lowercase\n",
    "# basically A.B.LastNameMaybeMore\n",
    "\n",
    "\n",
    "# display(audible_df[~audible_df[\"author\"].str.contains(pat=r\"^Writtenby:( (([A-Z][a-z]+)+ | (([A-Z][.])+[A-Z][a-z]+))+[,]* )\")])\n",
    "# display(audible_df[audible_df[\"author\"].str.contains(pat=r\"^Writtenby:((([A-Z][.])+[A-Z][a-z]+)+[,]*)\")])\n",
    "display(audible_df[~audible_df[\"author\"].str.contains(pat=r\"^Writtenby:([A-Z][a-z]+)+\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check for inconsistencies in the formatting of the 'time' column\n",
    "# do they all have 'and'?\n",
    "display(audible_df[~audible_df['time'].str.contains(pat=r'and', regex=True)].head())\n",
    "# ok not all do\n",
    "\n",
    "# do they all follow the <numbers><space><letters> etc. pattern?\n",
    "display(audible_df[~audible_df['time'].str.contains(pat=r'^\\d+\\s+[A-Za-z]+')].head())\n",
    "\n",
    "# let's get the unique values:\n",
    "audible_df.loc[~audible_df['time'].str.contains(r'^\\d+\\s+[A-Za-z]+', regex=True), 'time'].unique()\n",
    "# ok seems like it always contains 'and', except if the value is 'Less than 1 minute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How often is the stars column 'Not rated yet', or some other string that doesn't contain a digit?\n",
    "display(audible_df[~audible_df['stars'].str.contains(r'\\d')].shape)\n",
    "# wow that's a lot of books that aren't rated yet!\n",
    "display(audible_df[~audible_df['stars'].str.contains(r'\\d')])\n",
    "\n",
    "# what unique values are there?\n",
    "audible_df[~audible_df['stars'].str.contains(r'\\d')]['stars'].unique()\n",
    "# ok seems to just be 'Not rated yet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the release date column always follow the pattern <numbers> - <numbers> - <numbers>?\n",
    "display(audible_df[~audible_df['releasedate'].str.contains(r'^\\d+-\\d+-\\d+', regex=True)])\n",
    "# Ok nice they all follow that pattern\n",
    "\n",
    "display(audible_df[~audible_df['releasedate'].str.contains(r'^\\d{2}-\\d{2}-\\d{4}', regex=True)])\n",
    "# but it appears they don't always follow DD-MM-YYYY, sometimes it is D-M-YYYY, and sometimes it is just YY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the ****third dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Goodreads dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Audible dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a deep copy\n",
    "cleaned_audible_df = audible_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the price column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's look for outliers in the price\n",
    "\n",
    "# first let's convert it to a float\n",
    "# since there are commas in the numbers, e.g. 1,234.00, we will have to get rid of commas\n",
    "# display(audible_df['price'].min())\n",
    "\n",
    "# TODO: more to do here!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: !!!!! have to deal with weird character encoding issues in the audible dataset as well\n",
    "# like ç¬¬äºŒåäº”è©±ã‚µãƒ³ãƒ»ãƒŸã‚·ã‚§ãƒ«ã®ã„ã„ã...\tWrittenby:æ£®æœ¬å“²éƒŽ\tNarratedby:å°é‡Žç”°è‹±ä¸€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the author and narrator columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In my exploration I found that every row in the author and narrator column started with\n",
    "# 'Writtenby:' and 'Narratedby:', so let's remove that\n",
    "\n",
    "# replace 'Writtenby:' with an empty string\n",
    "cleaned_audible_df['author'] = cleaned_audible_df['author'].str.replace(pat=r'^Writtenby:', repl='', regex=True)\n",
    "\n",
    "# replace 'Narrattedby:' with an empty string\n",
    "cleaned_audible_df['narrator'] = cleaned_audible_df['narrator'].str.replace(pat=r'^Narratedby:', repl='', regex=True)\n",
    "\n",
    "display(cleaned_audible_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the releasedate column (converting to timestamp):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the release date to a datetime object\n",
    "# **Important note, they seem to be in a DD-MM-YYYY (or sometimes D-M-YY, etc. but day first) format, \n",
    "# since there are some dates like 30-10-18, 25-11-14 (so the day must be first), but there is also 1-5-2018\n",
    "cleaned_audible_df['cleaned_releasedate'] = pd.to_datetime(cleaned_audible_df['releasedate'], dayfirst=True, format='mixed')\n",
    "\n",
    "# temporarily display a lot of rows to check it worked\n",
    "with pd.option_context(\"display.min_rows\", 10):\n",
    "\t# look at just rows where releasedate had a weird format to especially make sure it worked for those\n",
    "\tdisplay(cleaned_audible_df[~cleaned_audible_df['releasedate'].str.contains(r'\\d{2}-\\d{2}-\\d{4}', regex=True)])\n",
    "\tdisplay(cleaned_audible_df)\n",
    "\n",
    "# ok seems to have worked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure there are no weird values in cleaned_releasedate\n",
    "print(\"min release date values:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] == cleaned_audible_df['cleaned_releasedate'].min()])\n",
    "# ok the min values look reasonable\n",
    "\n",
    "# check books that were released after today's date\n",
    "print(\"release date values that are after today's date:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] > pd.to_datetime('today').normalize()])\n",
    "# I don't think this is a mistake since one of the original releasedate values is '9-8-2024'\n",
    "# These have very weird character encoding issues and I don't think it makes sense to have books that aren't release yet\n",
    "# so I'm going to drop these\n",
    "\n",
    "cleaned_audible_df = cleaned_audible_df[cleaned_audible_df['cleaned_releasedate'] <= pd.to_datetime('today').normalize()]\n",
    "print(\"new max release date value:\")\n",
    "display(cleaned_audible_df['cleaned_releasedate'].max())\n",
    "# ok nice, now the max value was released about 2 weeks ago, that seems reasonable\n",
    "\n",
    "# now let's drop the releasedate column\n",
    "cleaned_audible_df.drop(columns=['releasedate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the time column and extracting hours and mins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt at converting the time column by splitting it into hours, mins, etc. components in different columns and then combining again\n",
    "print(\"df with the hours extracted:\")\n",
    "display(cleaned_audible_df['time'].str.extract(pat=r'([A-Za-z]+\\s*)+')[0].unique())\n",
    "\n",
    "# at the start of the string, get one or more digits, then a white space, hr, maybe an s\n",
    "# but only keep the digits\n",
    "# i.e. we get '8 hrs' or '1 hr' and we only keep the 8 or 1\n",
    "cleaned_audible_df['hours'] = cleaned_audible_df['time'].str.extract(pat=r'^(\\d+)\\shr[s]*')\n",
    "# seems to have worked\n",
    "# we have an NA if it is 0 hours, so let's fill the NAs with 0's\n",
    "cleaned_audible_df['hours'] = cleaned_audible_df['hours'].fillna(0)\n",
    "\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# check that it worked for when it is just '1 hr', not hrs\n",
    "print(\"rows with time == '1 hr':\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['time'] == '1 hr'])\n",
    "\n",
    "# check that the fillNA worked correctly\n",
    "print(\"rows with 0 in the hours column:\")\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df[cleaned_audible_df['hours'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the minutes\n",
    "# cleaned_audible_df['minutes'] = cleaned_audible_df['time'].str.extract(r'')\n",
    "cleaned_audible_df[cleaned_audible_df['time'].str.contains(r'min$', regex=True)]\n",
    "# ok it seems we have to be careful with not getting 'Less than 1 minute' and something like '1 hr and 1 min' mixed up\n",
    "\n",
    "# one or more digits, then 1 whitespace, then 'min', then maybe an s, all this at the end of the string\n",
    "# only capture the digits though\n",
    "# it is important that it's at the end of the string so we don't accidentally capture the 1 from 'Less than 1 minute', \n",
    "# we only want the number when the string ends in min or mins\n",
    "print(\"df with minutes extracted:\")\n",
    "cleaned_audible_df['minutes'] = cleaned_audible_df['time'].str.extract(r'(\\d+)\\smin[s]*$')\n",
    "# cleaned_audible_df[cleaned_audible_df['time'].str.contains(r'(\\d+\\smin[s]*$)')]\n",
    "\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)\n",
    "\n",
    "# check that it correctly did NA for rows where there are no minutes\n",
    "print(\"rows with NA in the minutes column:\")\n",
    "display(cleaned_audible_df[cleaned_audible_df['minutes'].isna()])\n",
    "\n",
    "# the minutes column seems to have worked nicely, let's fill in the NAs with 0's\n",
    "cleaned_audible_df['minutes'] = cleaned_audible_df['minutes'].fillna(0)\n",
    "\n",
    "print(\"df with minutes NAs filled in with 0's:\")\n",
    "# with pd.option_context(\"display.min_rows\", 10000):\n",
    "display(cleaned_audible_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what to do with rows where it is 'Less than 1 minute'????\n",
    "# let's see what unique values there are in the time column where we got NA for both hours and mins, and filled them both in with 0's:\n",
    "cleaned_audible_df[(cleaned_audible_df['hours'] == 0) & (cleaned_audible_df['minutes'] == 0)]['time'].unique()\n",
    "# Ok, just 'Less than 1 minute'. I will have to figure out how to take care of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the ****third dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrate the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
